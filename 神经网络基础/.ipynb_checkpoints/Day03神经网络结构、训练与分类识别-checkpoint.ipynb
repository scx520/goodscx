{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 特征学习的总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 定义与初始化需要训练的权重系统【重复】\n",
    "    - 一个张量是否可训练（requires_grad=True）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 根据神经网络的模型，做前向计算 【核心】\n",
    "    - 预测值-> softmax/sigmoid转换为概率 -> 使用最大分量下标作为分类的结果，值作为分类的概率\n",
    "        - 做概率阈值过滤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 根据预测值与真实值做损失计算【核心】\n",
    "    - 保证损失最小。\n",
    "    - 梯度下降"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 对损失值求导 【关键】\n",
    "    - 利用导数与学习率更新我你们的可训练权重系数 【重复】"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 最终得到一组训练好的权重：\n",
    "    - 对分类是最有利"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. PyTorch神经网络结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Layer(运算与权重系数 =  Layer【固化了可训练的参数】)\n",
    "    | - Conv2D\n",
    "    | - MaxPool2D\n",
    "    | - Relu\n",
    "    | - Linear\n",
    "    | - .....\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. conv2d Layer\n",
    "    - 运算固化\n",
    "        - 通过重载实现重定义forward(x)\n",
    "            - 提供可调用对象\n",
    "            conv = Conv2d(....)\n",
    "            y =conv.forward(x)  === y = conv(x)\n",
    "    - 运算的权重系数自动的管理\n",
    "        - 在构造器实现自动跟踪：\n",
    "            - self.任何便layer中的参数被自动跟踪\n",
    "    - 基本上所有的函数都封装成Layer\n",
    "    - 系数访问：parameters()返回所有权重矩阵张量\n",
    "    - 注意：\n",
    "        - 使用PyTorch的实现基本上满足95%的需求"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import  *\n",
    "# help(Conv2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Module封装\n",
    "    - 自动构建权重\n",
    "    - 自动跟踪可训练参数（self.layer）\n",
    "    - forward用户的运算实现接口（layer必须在构造器调用，必须是成员，这样定义的layer的参数才会被跟踪）\n",
    "        - 可调用对象\n",
    "    - 参数的返回访问"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 编程模式：\n",
    "    - layer实现具体的运算\n",
    "        - 继承Layer实现自己的运算（层）\n",
    "        - 直接使用Pytorch提供的Layer\n",
    "    - Module来把各种Layer组装为网络结构\n",
    "        - 继承Module使用Layer拼装各种网络结构\n",
    "    - 损失函数\n",
    "        - 调用损失Layer\n",
    "    - 权重更新\n",
    "        - Optimizier（Adam, SGD, .....）:对学习率的处理（学习率是固定）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import MSELoss\n",
    "# help(MSELoss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 总结：\n",
    "    - 模型（必须）\n",
    "    - 数据集（必须）\n",
    "    - 训练过程（必须）\n",
    "    - 识别封装\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 图像数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 数据集规范\n",
    "    - | - 数据集目录\n",
    "        - |- 类别名\n",
    "            - | - 图像1\n",
    "            - | - 图像2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 查看ImageFolder类型\n",
    "    - Method resolution order:\n",
    "        - ImageFolder\n",
    "            - DatasetFolder\n",
    "                - torchvision.datasets.vision.VisionDataset\n",
    "                    - torch.utils.data.dataset.Dataset\n",
    "                        - builtins.object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class ImageFolder in module torchvision.datasets.folder:\n",
      "\n",
      "class ImageFolder(DatasetFolder)\n",
      " |  A generic data loader where the images are arranged in this way: ::\n",
      " |  \n",
      " |      root/dog/xxx.png\n",
      " |      root/dog/xxy.png\n",
      " |      root/dog/xxz.png\n",
      " |  \n",
      " |      root/cat/123.png\n",
      " |      root/cat/nsdf3.png\n",
      " |      root/cat/asd932_.png\n",
      " |  \n",
      " |  Args:\n",
      " |      root (string): Root directory path.\n",
      " |      transform (callable, optional): A function/transform that  takes in an PIL image\n",
      " |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      " |      target_transform (callable, optional): A function/transform that takes in the\n",
      " |          target and transforms it.\n",
      " |      loader (callable, optional): A function to load an image given its path.\n",
      " |      is_valid_file (callable, optional): A function that takes path of an Image file\n",
      " |          and check if the file is a valid file (used to check of corrupt files)\n",
      " |  \n",
      " |   Attributes:\n",
      " |      classes (list): List of the class names.\n",
      " |      class_to_idx (dict): Dict with items (class_name, class_index).\n",
      " |      imgs (list): List of (image path, class_index) tuples\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      ImageFolder\n",
      " |      DatasetFolder\n",
      " |      torchvision.datasets.vision.VisionDataset\n",
      " |      torch.utils.data.dataset.Dataset\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, root, transform=None, target_transform=None, loader=<function default_loader at 0x000001FE9575ABF8>, is_valid_file=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from DatasetFolder:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Args:\n",
      " |          index (int): Index\n",
      " |      \n",
      " |      Returns:\n",
      " |          tuple: (sample, target) where target is class_index of the target class.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  extra_repr(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      " |  \n",
      " |  __add__(self, other)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "help(ImageFolder)\n",
    "# from torch.utils.data.dataset import Dataset\n",
    "# help(Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 经典的卷积神经网络实现图像分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 换一个网络模型\n",
    "    - resnet18\n",
    "    - googlet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  GPU的使用\n",
    "2. Module.train() + Module.eval()\n",
    "    - BatchNorm \n",
    "    - Dropout\n",
    "    - 注意：\n",
    "        - 仅仅在训练的时候使用，在测试的时候不需要使用(干扰我们的测试效果)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
      "             ReLU-37          [-1, 256, 14, 14]               0\n",
      "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
      "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
      "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
      "             ReLU-49          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 11,689,512\n",
      "Trainable params: 11,689,512\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 62.79\n",
      "Params size (MB): 44.59\n",
      "Estimated Total Size (MB): 107.96\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet18\n",
    "from torchsummary import summary\n",
    "\n",
    "net_18 = resnet18()\n",
    "print(summary(net_18, input_size=(3, 224, 224), device=\"cpu\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function train in module torch.nn.modules.module:\n",
      "\n",
      "train(self, mode=True)\n",
      "    Sets the module in training mode.\n",
      "    \n",
      "    This has any effect only on certain modules. See documentations of\n",
      "    particular modules for details of their behaviors in training/evaluation\n",
      "    mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      "    etc.\n",
      "    \n",
      "    Args:\n",
      "        mode (bool): whether to set training mode (``True``) or evaluation\n",
      "                     mode (``False``). Default: ``True``.\n",
      "    \n",
      "    Returns:\n",
      "        Module: self\n",
      "\n",
      "Help on function eval in module torch.nn.modules.module:\n",
      "\n",
      "eval(self)\n",
      "    Sets the module in evaluation mode.\n",
      "    \n",
      "    This has any effect only on certain modules. See documentations of\n",
      "    particular modules for details of their behaviors in training/evaluation\n",
      "    mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      "    etc.\n",
      "    \n",
      "    This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
      "    \n",
      "    Returns:\n",
      "        Module: self\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from  torch.nn import Module\n",
    "help(Module.train)\n",
    "help(Module.eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 总结：\n",
    "    - 图像分类的数据集的处理\n",
    "    - 训练的模式\n",
    "    - 分类识别方式\n",
    "        - 图像的预处理（一定与训练时候的图像处理保持一致）\n",
    "        - Module.train与eval的作用与影响\n",
    "    - 常见的经典卷积神经网络：图像分类\n",
    "        - 了解其结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 作业：\n",
    "    1. 利用我们给你们的人脸采集程序，采集至少4个人的人脸\n",
    "    2. 使用resnet18训练一个AI模型\n",
    "    3. 使用这个模型识别人脸，体验其准确度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
